{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Clasificación AACC vs no AACC con Machine Learning\n",
    "Este notebook compara distintos clasificadores usando datos EEG.\n",
    "Incluye preprocesamiento, reducción con PCA y validación cruzada.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Librerías y configuración\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📁 Carga de datos\n",
    "X = pd.read_csv(\"C:/Users/Eloy/OneDrive - Universidad de Castilla-La Mancha (1)/Tesis_EEG/proyecto_eeg/df_EEG/PRE/X_gamma.csv\", index_col=0)\n",
    "df_meta = pd.read_csv(\"C:/Users/Eloy/OneDrive - Universidad de Castilla-La Mancha (1)/Tesis_EEG/proyecto_eeg/df_EEG/PRE/meta.csv\", index_col=0)\n",
    "\n",
    "# Filtrar IDs comunes\n",
    "ids_validos = X.index.intersection(df_meta.index)\n",
    "X = X.loc[ids_validos]\n",
    "y = df_meta.loc[ids_validos][\"y_recommended\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ PCA redujo de 576 a 26 dimensiones\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ⚙️ Preprocesamiento\n",
    "X = X.select_dtypes(include='number')\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=0.9, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(f\"➡️ PCA redujo de {X.shape[1]} a {X_pca.shape[1]} dimensiones\")\n",
    "\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Definir clasificadores y parámetros\n",
    "modelos = {\n",
    "    \"SVM\": (\n",
    "        SVC(class_weight='balanced', random_state=42),\n",
    "        {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": [\"linear\", \"rbf\"],\n",
    "            \"gamma\": [\"scale\", \"auto\"]\n",
    "        }\n",
    "    ),\n",
    "    \"Random Forest\": (\n",
    "        RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10, 20]\n",
    "        }\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [3, 5, 7],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "        }\n",
    "    ),\n",
    "    \"Logistic Regression\": (\n",
    "        LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "        {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"penalty\": [\"l2\"]\n",
    "        }\n",
    "    ),\n",
    "    \"KNN\": (\n",
    "        KNeighborsClassifier(),\n",
    "        {\n",
    "            \"n_neighbors\": [3, 5, 7]\n",
    "        }\n",
    "    ),\n",
    "    \"Decision Tree\": (\n",
    "        DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "        {\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    ),\n",
    "    \"Naive Bayes\": (\n",
    "        GaussianNB(),\n",
    "        {}\n",
    "    ),\n",
    "    \"Gradient Boosting\": (\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1],\n",
    "            \"max_depth\": [3, 5]\n",
    "        }\n",
    "    ),\n",
    "    \"AdaBoost\": (\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"learning_rate\": [0.5, 1.0]\n",
    "        }\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 GridSearchCV para: SVM\n",
      "🔍 GridSearchCV para: Random Forest\n",
      "🔍 GridSearchCV para: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 GridSearchCV para: Logistic Regression\n",
      "🔍 GridSearchCV para: KNN\n",
      "🔍 GridSearchCV para: Decision Tree\n",
      "🔍 GridSearchCV para: Naive Bayes\n",
      "🔍 GridSearchCV para: Gradient Boosting\n",
      "🔍 GridSearchCV para: AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# 🔎 Evaluación de modelos\n",
    "resultados = []\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for nombre, (modelo, param_grid) in modelos.items():\n",
    "    print(f\"🔍 GridSearchCV para: {nombre}\")\n",
    "    grid = GridSearchCV(modelo, param_grid, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best = grid.best_estimator_\n",
    "    scores_f1 = cross_val_score(best, X_pca, y, cv=cv, scoring='f1_macro')\n",
    "    scores_acc = cross_val_score(best, X_pca, y, cv=cv, scoring='accuracy')\n",
    "    resultados.append({\n",
    "        'Modelo': nombre,\n",
    "        'Mejor Parámetro': grid.best_params_,\n",
    "        'F1 Macro (CV)': scores_f1.mean(),\n",
    "        'Accuracy (CV)': scores_acc.mean()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Mejor Parámetro</th>\n",
       "      <th>F1 Macro (CV)</th>\n",
       "      <th>Accuracy (CV)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.620886</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.553664</td>\n",
       "      <td>0.555844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.551953</td>\n",
       "      <td>0.558009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.546490</td>\n",
       "      <td>0.555844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50}</td>\n",
       "      <td>0.535891</td>\n",
       "      <td>0.537229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.526750</td>\n",
       "      <td>0.528139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.525678</td>\n",
       "      <td>0.563203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10}</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.508935</td>\n",
       "      <td>0.527706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo                                    Mejor Parámetro  \\\n",
       "0                  SVM        {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "1        Random Forest           {'max_depth': None, 'n_estimators': 100}   \n",
       "2    Gradient Boosting  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "3  Logistic Regression                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "4             AdaBoost         {'learning_rate': 0.5, 'n_estimators': 50}   \n",
       "5              XGBoost  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "6          Naive Bayes                                                 {}   \n",
       "7        Decision Tree       {'max_depth': None, 'min_samples_split': 10}   \n",
       "8                  KNN                                 {'n_neighbors': 7}   \n",
       "\n",
       "   F1 Macro (CV)  Accuracy (CV)  \n",
       "0       0.620886       0.628571  \n",
       "1       0.553664       0.555844  \n",
       "2       0.551953       0.558009  \n",
       "3       0.546490       0.555844  \n",
       "4       0.535891       0.537229  \n",
       "5       0.526750       0.528139  \n",
       "6       0.525678       0.563203  \n",
       "7       0.521246       0.528571  \n",
       "8       0.508935       0.527706  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📈 Mostrar resultados ordenados por F1 Macro\n",
    "df_resultados = pd.DataFrame(resultados).sort_values(by='F1 Macro (CV)', ascending=False)\n",
    "df_resultados.reset_index(drop=True, inplace=True)\n",
    "df_resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
