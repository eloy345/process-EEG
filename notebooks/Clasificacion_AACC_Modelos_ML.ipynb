{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clasificaci贸n AACC vs no AACC con Machine Learning\n",
    "Este notebook compara distintos clasificadores usando datos EEG.\n",
    "Incluye preprocesamiento, reducci贸n con PCA y validaci贸n cruzada.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Librer铆as y configuraci贸n\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Carga de datos\n",
    "X = pd.read_csv(\"C:/Users/Eloy/OneDrive - Universidad de Castilla-La Mancha (1)/Tesis_EEG/proyecto_eeg/df_EEG/PRE/X_gamma.csv\", index_col=0)\n",
    "df_meta = pd.read_csv(\"C:/Users/Eloy/OneDrive - Universidad de Castilla-La Mancha (1)/Tesis_EEG/proyecto_eeg/df_EEG/PRE/meta.csv\", index_col=0)\n",
    "\n",
    "# Filtrar IDs comunes\n",
    "ids_validos = X.index.intersection(df_meta.index)\n",
    "X = X.loc[ids_validos]\n",
    "y = df_meta.loc[ids_validos][\"y_recommended\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★ PCA redujo de 576 a 26 dimensiones\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 锔 Preprocesamiento\n",
    "X = X.select_dtypes(include='number')\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=0.9, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(f\"★ PCA redujo de {X.shape[1]} a {X_pca.shape[1]} dimensiones\")\n",
    "\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Definir clasificadores y par谩metros\n",
    "modelos = {\n",
    "    \"SVM\": (\n",
    "        SVC(class_weight='balanced', random_state=42),\n",
    "        {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": [\"linear\", \"rbf\"],\n",
    "            \"gamma\": [\"scale\", \"auto\"]\n",
    "        }\n",
    "    ),\n",
    "    \"Random Forest\": (\n",
    "        RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10, 20]\n",
    "        }\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [3, 5, 7],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "        }\n",
    "    ),\n",
    "    \"Logistic Regression\": (\n",
    "        LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "        {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"penalty\": [\"l2\"]\n",
    "        }\n",
    "    ),\n",
    "    \"KNN\": (\n",
    "        KNeighborsClassifier(),\n",
    "        {\n",
    "            \"n_neighbors\": [3, 5, 7]\n",
    "        }\n",
    "    ),\n",
    "    \"Decision Tree\": (\n",
    "        DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "        {\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    ),\n",
    "    \"Naive Bayes\": (\n",
    "        GaussianNB(),\n",
    "        {}\n",
    "    ),\n",
    "    \"Gradient Boosting\": (\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1],\n",
    "            \"max_depth\": [3, 5]\n",
    "        }\n",
    "    ),\n",
    "    \"AdaBoost\": (\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"learning_rate\": [0.5, 1.0]\n",
    "        }\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GridSearchCV para: SVM\n",
      " GridSearchCV para: Random Forest\n",
      " GridSearchCV para: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Eloy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:02:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GridSearchCV para: Logistic Regression\n",
      " GridSearchCV para: KNN\n",
      " GridSearchCV para: Decision Tree\n",
      " GridSearchCV para: Naive Bayes\n",
      " GridSearchCV para: Gradient Boosting\n",
      " GridSearchCV para: AdaBoost\n"
     ]
    }
   ],
   "source": [
    "#  Evaluaci贸n de modelos\n",
    "resultados = []\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for nombre, (modelo, param_grid) in modelos.items():\n",
    "    print(f\" GridSearchCV para: {nombre}\")\n",
    "    grid = GridSearchCV(modelo, param_grid, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best = grid.best_estimator_\n",
    "    scores_f1 = cross_val_score(best, X_pca, y, cv=cv, scoring='f1_macro')\n",
    "    scores_acc = cross_val_score(best, X_pca, y, cv=cv, scoring='accuracy')\n",
    "    resultados.append({\n",
    "        'Modelo': nombre,\n",
    "        'Mejor Par谩metro': grid.best_params_,\n",
    "        'F1 Macro (CV)': scores_f1.mean(),\n",
    "        'Accuracy (CV)': scores_acc.mean()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Mejor Par谩metro</th>\n",
       "      <th>F1 Macro (CV)</th>\n",
       "      <th>Accuracy (CV)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.620886</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.553664</td>\n",
       "      <td>0.555844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.551953</td>\n",
       "      <td>0.558009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.546490</td>\n",
       "      <td>0.555844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50}</td>\n",
       "      <td>0.535891</td>\n",
       "      <td>0.537229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.526750</td>\n",
       "      <td>0.528139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.525678</td>\n",
       "      <td>0.563203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10}</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.508935</td>\n",
       "      <td>0.527706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo                                    Mejor Par谩metro  \\\n",
       "0                  SVM        {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
       "1        Random Forest           {'max_depth': None, 'n_estimators': 100}   \n",
       "2    Gradient Boosting  {'learning_rate': 0.05, 'max_depth': 5, 'n_est...   \n",
       "3  Logistic Regression                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "4             AdaBoost         {'learning_rate': 0.5, 'n_estimators': 50}   \n",
       "5              XGBoost  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
       "6          Naive Bayes                                                 {}   \n",
       "7        Decision Tree       {'max_depth': None, 'min_samples_split': 10}   \n",
       "8                  KNN                                 {'n_neighbors': 7}   \n",
       "\n",
       "   F1 Macro (CV)  Accuracy (CV)  \n",
       "0       0.620886       0.628571  \n",
       "1       0.553664       0.555844  \n",
       "2       0.551953       0.558009  \n",
       "3       0.546490       0.555844  \n",
       "4       0.535891       0.537229  \n",
       "5       0.526750       0.528139  \n",
       "6       0.525678       0.563203  \n",
       "7       0.521246       0.528571  \n",
       "8       0.508935       0.527706  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Mostrar resultados ordenados por F1 Macro\n",
    "df_resultados = pd.DataFrame(resultados).sort_values(by='F1 Macro (CV)', ascending=False)\n",
    "df_resultados.reset_index(drop=True, inplace=True)\n",
    "df_resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
